// With this script, we can examine the runtime of each parts of the query execution. Therefore,
// the database internal database internal measurements are used most of the time. In order to create a mapping
// between the SQL command entered and the single operator tasks, there are some probes storing the ids (*this*)
// of the appropriate objects.

global pipeline_creation_time
global parsing_time

global tasks_per_statement
global task_list
global operator_task_list
global operator_statistics
global operator_name
global times

global counter = 0

// If debug is enabled, the executed operators will be printed immidiately to the console
global debug = 0


probe begin
{
    printf("Probing binary %s\n", @1)
}

// Creation of a new SQL pipeline has started
probe process(@1).provider("HYRISE").mark("CREATE_PIPELINE")
{
    pipeline_creation_time[$arg1] = gettimeofday_us()
}

// SQL string parsing
probe process(@1).provider("HYRISE").mark("SQL_PARSING")
{
    parsing_time[user_string($arg1)] = $arg2
}

// Pipeline creation done
probe process(@1).provider("HYRISE").mark("PIPELINE_CREATION_DONE")
{
    creation_time = gettimeofday_us() - pipeline_creation_time[$arg3]
    printf("\nSQL parsed within %i μs\n"
           "Statement contains %i statement(s)\n"
           "Overall pipeline creation time: %i μs\n\n", parsing_time[user_string($arg2)], $arg1, creation_time);
}

// This probe gets executed as soon as a query fully executed
probe process(@1).provider("HYRISE").mark("SUMMARY")
{
    tasks_for_specific_id = tasks_per_statement[$arg8]
        printf("\n================================================================\n"
               "SUMMARY:\nQuery: %s\n"
               "----------------------------------------------------------------\n"
               "\tTranslation time: %s μs\n"
               "\tOptimization time: %i μs\n"
               "\tLQP translation time: %i μs\n"
               "\tQuery plan cached: %s\n"
               "\tAmount of tasks initially scheduled: %i\n"
               "\tQuery execution time: %i μs\n"
               "\tOperator execution times (preserved order):\n"
               , user_string($arg1), $arg2, $arg3, $arg4, $arg6 ? "yes" : "no", $arg7, $arg5
            )

        // Since we have to use a map and iterate over it, performance might go down after a certain time
        foreach (task_id = [tid, counter+] in task_list) {
            if (tasks_for_specific_id == tid) {
                operator_id = operator_task_list[task_id]
                printf("\t\t%s: %i μs        Fetched %i row(s) / %i chunk(s)\n", 
                    operator_name[operator_id],
                    operator_statistics[operator_id, "runtime"],
                    operator_statistics[operator_id, "rows"],
                    operator_statistics[operator_id, "chunks"])
                times[operator_name[operator_id]] <<< operator_statistics[operator_id, "runtime"]
            }
        }

        println("\nSum of execution time per operator:")
        foreach (time in times) {
            printf("\t%s execution time: %i μs (%i times called)\n", time, @sum(times[time]), @count(times[time]))
        }

        delete times[operator_name[operator_id]]
        printf("================================================================\n\n")
}


// Get id of the vector containing the tasks
probe process(@1).provider("HYRISE").mark("TASKS_PER_STATEMENT")
{
    if (debug) printf("(debug) Working on query %s\n", user_string($arg2));
    tasks_per_statement[$arg3] = $arg1
}

// Store each task id
probe process(@1).provider("HYRISE").mark("TASKS")
{
    // Storing the ids in a regular array would be nice, but SystemTap cannot iterate over it.
    // Hence, we have to use an ugly map.
    task_list[$arg1, counter++] = $arg2
}

// Mapping between AbstractTask and OperatorTask
probe process(@1).provider("HYRISE").mark("OPERATOR_TASKS")
{
    operator_task_list[$arg2] = $arg1
}

// Store performance statistics of each operator executed
probe process(@1).provider("HYRISE").mark("OPERATOR_EXECUTED")
{
    operator_name[$arg5] = user_string($arg1)
    operator_statistics[$arg5, "runtime"] = $arg2
    operator_statistics[$arg5, "rows"] = $arg3
    operator_statistics[$arg5, "chunks"] = $arg4
    if (debug) printf("(debug) Operator %s executed : %i μs\n", user_string($arg1), $arg2)
}

probe process(@1).provider("HYRISE").mark("OPERATOR_STARTED")
{
 if(debug) printf("(debug) Starting execution of operator %s\n", user_string($arg1));
}
